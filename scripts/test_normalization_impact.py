#!/usr/bin/env python3
"""
Quick test: Does L2 normalization improve K-Means clustering?
"""
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score
from collections import Counter

print('=' * 80)
print('ğŸ§ª å®éªŒ: å½’ä¸€åŒ–åµŒå…¥å K-Means æ€§èƒ½')
print('=' * 80)
print()

# åŠ è½½æ•°æ®
print('ğŸ“Š åŠ è½½æ•°æ®...')
embeddings = np.load('data/embeddings/train_embeddings.npy')
from datasets import load_dataset
dataset = load_dataset('ag_news', split='train')
true_labels = np.array([item['label'] for item in dataset])
print(f'   åŠ è½½äº† {len(embeddings)} ä¸ªåµŒå…¥å‘é‡')
print()

# åŸå§‹åµŒå…¥ï¼ˆæœªå½’ä¸€åŒ–ï¼‰æ€§èƒ½
print('ğŸ” æµ‹è¯• 1: åŸå§‹åµŒå…¥ï¼ˆæœªå½’ä¸€åŒ–ï¼‰')
print('   è¿è¡Œ K-Means...')
kmeans_original = KMeans(n_clusters=4, random_state=42, init='k-means++', n_init=1, max_iter=100)
labels_original = kmeans_original.fit_predict(embeddings)

# è®¡ç®— Silhouette Scoreï¼ˆé‡‡æ ·åŠ é€Ÿï¼‰
sample_size = min(10000, len(embeddings))
np.random.seed(42)
sample_idx = np.random.choice(len(embeddings), sample_size, replace=False)
silhouette_original = silhouette_score(embeddings[sample_idx], labels_original[sample_idx])

# è®¡ç®—çº¯åº¦
purities_original = []
for cluster_id in range(4):
    mask = labels_original == cluster_id
    cluster_true_labels = true_labels[mask]
    if len(cluster_true_labels) > 0:
        most_common = Counter(cluster_true_labels).most_common(1)[0][1]
        purity = most_common / len(cluster_true_labels)
        purities_original.append(purity)
avg_purity_original = np.mean(purities_original)

print(f'   âœ… å®Œæˆ')
print(f'   Silhouette Score: {silhouette_original:.6f}')
print(f'   èšç±»çº¯åº¦: {avg_purity_original:.4f} ({avg_purity_original*100:.2f}%)')
print()

# å½’ä¸€åŒ–åµŒå…¥åçš„æ€§èƒ½
print('ğŸ” æµ‹è¯• 2: å½’ä¸€åŒ–åµŒå…¥ï¼ˆL2 normalizationï¼‰')
print('   å¯¹åµŒå…¥è¿›è¡Œ L2 å½’ä¸€åŒ–...')
embeddings_normalized = normalize(embeddings, norm='l2')
print(f'   å½’ä¸€åŒ–åçš„èŒƒæ•°: {np.linalg.norm(embeddings_normalized[0]):.6f} (åº”è¯¥ â‰ˆ 1.0)')
print('   è¿è¡Œ K-Means...')

kmeans_normalized = KMeans(n_clusters=4, random_state=42, init='k-means++', n_init=1, max_iter=100)
labels_normalized = kmeans_normalized.fit_predict(embeddings_normalized)

# è®¡ç®—æŒ‡æ ‡
silhouette_normalized = silhouette_score(embeddings_normalized[sample_idx], labels_normalized[sample_idx])

purities_normalized = []
for cluster_id in range(4):
    mask = labels_normalized == cluster_id
    cluster_true_labels = true_labels[mask]
    if len(cluster_true_labels) > 0:
        most_common = Counter(cluster_true_labels).most_common(1)[0][1]
        purity = most_common / len(cluster_true_labels)
        purities_normalized.append(purity)
avg_purity_normalized = np.mean(purities_normalized)

print(f'   âœ… å®Œæˆ')
print(f'   Silhouette Score: {silhouette_normalized:.6f}')
print(f'   èšç±»çº¯åº¦: {avg_purity_normalized:.4f} ({avg_purity_normalized*100:.2f}%)')
print()

# å¯¹æ¯”ç»“æœ
print('=' * 80)
print('ğŸ“Š ç»“æœå¯¹æ¯”')
print('=' * 80)
print()
print(f'{"æŒ‡æ ‡":<20} | {"åŸå§‹åµŒå…¥":>12} | {"å½’ä¸€åŒ–åµŒå…¥":>12} | {"æ”¹è¿›":>10}')
print('-' * 70)
print(f'{"Silhouette Score":<20} | {silhouette_original:12.6f} | {silhouette_normalized:12.6f} | {((silhouette_normalized - silhouette_original) / abs(silhouette_original + 1e-10) * 100):+9.1f}%')
print(f'{"èšç±»çº¯åº¦":<20} | {avg_purity_original:12.4f} | {avg_purity_normalized:12.4f} | {((avg_purity_normalized - avg_purity_original) / avg_purity_original * 100):+9.1f}%')
print()

# ç»“è®º
print('=' * 80)
print('ğŸ’¡ ç»“è®º')
print('=' * 80)
improvement_pct = (avg_purity_normalized - avg_purity_original) / avg_purity_original * 100

if improvement_pct > 5:
    print('âœ… å½’ä¸€åŒ–æœ‰æ˜¾è‘—æ”¹å–„ï¼')
    print(f'   èšç±»çº¯åº¦æå‡: {(avg_purity_normalized - avg_purity_original)*100:.2f} ä¸ªç™¾åˆ†ç‚¹')
    print(f'   ç›¸å¯¹æ”¹è¿›: {improvement_pct:.1f}%')
elif improvement_pct > 0:
    print('âš ï¸ å½’ä¸€åŒ–æœ‰è½»å¾®æ”¹å–„')
    print(f'   èšç±»çº¯åº¦æå‡: {(avg_purity_normalized - avg_purity_original)*100:.2f} ä¸ªç™¾åˆ†ç‚¹')
    print(f'   ç›¸å¯¹æ”¹è¿›: {improvement_pct:.1f}%')
else:
    print('âŒ å½’ä¸€åŒ–æ²¡æœ‰æ”¹å–„')
    print('   é—®é¢˜ä¸åœ¨äºå½’ä¸€åŒ–ï¼Œè€Œæ˜¯æ›´æ ¹æœ¬çš„ç»´åº¦è¯…å’’')
print()
