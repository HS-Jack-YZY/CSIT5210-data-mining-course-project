# GMM 聚类实验报告
## AG News 文本分类研究 - 概率聚类方法

**作者：** Jack YUAN  
**课程：** CSIT5210 - 数据挖掘  
**日期：** 2025年11月10日  
**学校：** 香港科技大学

---

## 摘要

本报告系统性地研究了 GMM (Gaussian Mixture Model) 在 AG News 文本分类数据集上的应用，并与 K-Means、DBSCAN 进行对比分析。GMM 作为概率聚类方法，提供了软聚类和不确定性量化能力。

**主要发现：**
- GMM 在 AG News 嵌入空间中表现与 K-Means **几乎相同**
- 协方差类型对比：**Spherical 最优**（BIC 最低）
- 聚类质量指标：
  - Silhouette 分数：0.000743（略低于 K-Means 0.000804）
  - Davies-Bouldin 指数：26.29（略高于 K-Means 26.21）
  - 聚类纯度：**25.34%**（略高于 K-Means 25.28%，**优势 0.06%**）
- **不确定性分析揭示核心问题**：
  - 61.1% 文档置信度 < 0.5（高度不确定）
  - 平均置信度 0.485（接近随机 0.5）

**核心价值：**
GMM 的概率输出揭示了高维聚类失败的本质：模型对大部分文档的聚类分配高度不确定，证明问题在于数据本身不可聚类，而非算法选择。

---

## 1. 引言

### 1.1 研究背景

在前期实验中，K-Means 和 DBSCAN 在 AG News 聚类任务上均表现不佳。本研究探索 **GMM (Gaussian Mixture Model)** 作为概率聚类方法的潜力：

**GMM 相对优势：**
1. **软聚类**: 每个样本属于所有簇的概率分布
2. **不确定性量化**: 直接输出置信度分数
3. **灵活形状**: 支持椭圆形聚类（协方差类型可调）
4. **理论基础**: 基于概率生成模型

### 1.2 研究目标

**主要目标：**
- 用 GMM 对 120,000 篇新闻进行概率聚类
- 对比 4 种协方差类型（full, tied, diag, spherical）
- 量化聚类不确定性

**次要目标：**
- 对比 GMM 与 K-Means/DBSCAN 的性能
- 分析 GMM 在高维空间中的表现
- 提供聚类算法选择指导

### 1.3 数据集

**AG News 数据集：**
- 规模：120,000 训练，7,600 测试
- 类别：4 类均衡（World, Sports, Business, Sci/Tech）
- 嵌入：Gemini 768 维向量

**与前期实验一致性：**
使用完全相同的嵌入数据，确保公平对比。

---

## 2. 方法论

### 2.1 GMM 算法原理

**数学模型：**
```
P(x) = Σ[k=1..K] π_k * N(x | μ_k, Σ_k)
```
- π_k: 组件权重（Σπ_k = 1）
- N(x | μ_k, Σ_k): 高斯分布（均值 μ_k，协方差 Σ_k）
- K: 组件数量（本实验 K=4）

**EM 算法：**
1. **E-步**: 计算后验概率 γ_ik = P(z_i=k | x_i)
2. **M-步**: 更新参数 {π_k, μ_k, Σ_k}
3. 迭代直到收敛

**协方差类型：**
- **Full**: Σ_k 为完整协方差矩阵（768×768），参数最多
- **Tied**: 所有组件共享一个协方差矩阵
- **Diag**: 对角协方差矩阵（假设特征独立）
- **Spherical**: 球形协方差 Σ_k = σ_k² I，参数最少

### 2.2 实验流程

```
[1] 协方差类型对比 → [2] 最优模型拟合 → [3] 不确定性分析 →
[4] 质量评估 → [5] 与 K-Means/DBSCAN 对比 → [6] 可视化
```

### 2.3 协方差类型对比

**实验设计：**
- 测试 4 种协方差类型
- 评估标准：BIC（主要）、AIC、Silhouette
- 选择标准：BIC 最低（平衡拟合与复杂度）

**BIC 公式：**
```
BIC = -2·log(L) + p·log(n)
```
- L: 似然函数
- p: 参数数量
- n: 样本数（120,000）

### 2.4 不确定性分析

**置信度定义：**
```
confidence_i = max_k P(z_i=k | x_i)
```

**低置信度阈值：** 0.5
**混淆文档定义：** top2 概率差 < 0.2

### 2.5 评估指标

与 K-Means/DBSCAN 使用相同指标体系：
1. Silhouette Score
2. Davies-Bouldin Index
3. Cluster Purity
4. **GMM 特有**：BIC、AIC、置信度分布

---

## 3. 实验结果

### 3.1 协方差类型对比结果

| 协方差类型 | BIC | AIC | Silhouette | 收敛迭代 | 运行时间 |
|-----------|-----|-----|------------|----------|----------|
| **Spherical** | **261,588,873** | 261,559,024 | 0.000743 | 7 | 148s |
| Diag | 261,621,234 | **261,561,632** | 0.000549 | 8 | 147s |
| Tied | 264,746,194 | 261,853,408 | **0.000799** | 8 | 156s |
| Full | 274,162,457 | 262,680,768 | 0.000709 | 36 | 203s |

**选择依据：** Spherical BIC 最低 → 最优模型简洁性

**关键观察：**
1. **BIC 与 AIC 一致**: Spherical 和 Diag 接近最优
2. **Tied Silhouette 最高**: 但 BIC 过高（过拟合风险）
3. **Full 最差**: 参数过多（2,359,296 参数），BIC 最高
4. **Spherical 最快**: 参数最少（3,073 参数），收敛快

### 3.2 最优 GMM 聚类结果

**模型配置：**
- 协方差类型：Spherical
- 组件数：4
- 收敛状态：7 次迭代成功收敛
- 组件权重：[0.248, 0.252, 0.251, 0.249]（高度均衡）

**聚类发现：**
- 簇数量：4
- 簇大小：29,513 | 30,466 | 30,146 | 29,875（均衡）
- 噪声点：0

### 3.3 聚类质量指标

| 指标 | GMM | K-Means | DBSCAN | 相对表现 |
|------|-----|---------|--------|----------|
| Silhouette | 0.000743 | **0.000804** | N/A | K-Means +8.2% |
| Davies-Bouldin | 26.29 | **26.21** | N/A | K-Means 略优 |
| Purity | **0.2534** | 0.2528 | 0.2500 | **GMM +0.24%** |

**综合评价：**
GMM 与 K-Means 性能**统计上无显著差异**，但 GMM 略胜一筹（纯度高 0.06%）。

### 3.4 不确定性分析结果

**置信度统计：**
- 平均置信度：**0.485**（接近随机 0.5）
- 中位数：0.463
- 标准差：0.121
- 范围：[0.254, 0.999]

**低置信度文档：**
- 数量：**73,313**（**61.1%**）
- 定义：max_probability < 0.5

**混淆文档：**
- 数量：62,925（52.4%）
- 定义：top2 概率差 < 0.2

**类别级不确定性：**

| 类别 | 平均置信度 | 低置信度比例 |
|------|-----------|-------------|
| World | 0.485 | 60.97% |
| Sports | 0.485 | 60.97% |
| Business | 0.484 | 61.31% |
| Sci/Tech | 0.484 | 61.12% |

**关键发现：**
四个类别的不确定性几乎完全相同，说明问题是全局性的，而非某个类别特别难聚类。

---

## 4. 讨论

### 4.1 GMM 与 K-Means 对比

**性能差异：**
- Silhouette：K-Means 高 8.2%（0.000804 vs 0.000743）
- Davies-Bouldin：K-Means 低 0.3%（26.21 vs 26.29）
- Purity：GMM 高 0.24%（0.2534 vs 0.2528）

**结论：差异微小，实际上相同**

**为何 GMM 未能显著改善？**

1. **高维空间问题：**
   - 768 维中高斯假设同样受限
   - 协方差矩阵难以准确估计

2. **簇形状不重要：**
   - K-Means 球形假设 vs GMM 椭圆形
   - 数据无明显形状特征可利用

3. **EM 算法局部最优：**
   - 与 K-Means 类似的初始化敏感性
   - 收敛到相似的解

### 4.2 GMM 的独特价值：不确定性量化

**GMM 最大优势：揭示问题本质**

**61% 低置信度文档的含义：**
1. **模型高度不确定**: 对大部分文档无法给出confident分配
2. **数据不可聚类**: 如果数据有清晰聚类结构，置信度应 >0.7
3. **证明算法无罪**: 不是 GMM 或 K-Means 失败，是任务本身不可行

**对比 K-Means：**
- K-Means 强制硬分配，掩盖了不确定性
- GMM 诚实揭示："我不确定这个文档属于哪个簇"

### 4.3 协方差类型选择指导

**Spherical 为何最优？**

1. **奥卡姆剃刀原则：**
   - 最简单模型（最少参数）
   - 避免过拟合

2. **高维数据特性：**
   - 768 维空间中方差各向同性
   - 复杂协方差结构无法可靠估计

3. **实际验证：**
   - Full（最复杂）BIC 最高 → 过拟合
   - Spherical（最简单）BIC 最低 → 泛化最佳

**启示：**
高维数据聚类中，简单模型往往优于复杂模型。

### 4.4 GMM vs DBSCAN 对比

| 维度 | GMM | DBSCAN |
|------|-----|--------|
| 簇数量 | 4 ✅ | 1 ❌ |
| 质量指标 | 可计算 ✅ | 无法计算 ❌ |
| 纯度 | 25.34% | 25.00% (random) |
| 运行时间 | 815s | 238s |
| **结论** | **勉强可用** | **完全失败** |

GMM 虽然效果差，但至少产生了可分析的 4 簇结构。DBSCAN 连基本聚类都无法完成。

---

## 5. 可视化分析

### 5.1 协方差对比图

参见 `results/gmm_covariance_comparison.png`

**关键观察：**
- BIC/AIC 图：Spherical 明显最优
- Silhouette 图：四种类型接近（都很低）
- Runtime 图：Full 显著慢于其他

### 5.2 不确定性可视化

参见 `results/gmm_uncertainty_analysis.png`

**四象限分析：**
1. **置信度分布**：平均值 0.485 接近随机
2. **类别低置信度比例**：四类均 ~61%
3. **平均置信度对比**：四类几乎相同
4. **汇总统计**：61% 低置信度，52% 混淆文档

**视觉证据：**
置信度分布中心在 0.5 附近，说明 GMM 对大部分文档的分配接近"抛硬币"。

### 5.3 降维可视化

参见 `results/gmm_cluster_visualization.png`

**6 个子图对比：**
- **t-SNE/UMAP - GMM 簇**：4 个簇在 2D 投影中重叠
- **t-SNE/UMAP - 真实类别**：显示语义结构存在
- **t-SNE/UMAP - 置信度**：大部分点为黄色/绿色（中低置信度）

**关键洞察：**
置信度可视化显示高置信度区域（深绿）极少，证明 61% 低置信度不是统计偶然。

---

## 6. 结论

### 6.1 主要发现

1. **GMM 与 K-Means 性能相同**
   - 三个质量指标差异 <1%
   - 统计上无显著差异

2. **Spherical 协方差最优**
   - BIC 最低：261,588,873
   - 简单模型在高维数据中更鲁棒

3. **61% 文档低置信度**
   - 揭示聚类任务根本问题
   - 数据本身不可聚类的证据

4. **GMM 优于 DBSCAN，但仍失败**
   - 至少产生 4 簇结构
   - 纯度仅略高于随机

### 6.2 GMM 的价值定位

**GMM 何时使用？**
- ✅ 需要软聚类（概率分配）
- ✅ 需要不确定性量化
- ✅ 数据符合高斯混合假设
- ✅ 中低维数据（<100 维）

**GMM 何时避免？**
- ❌ 高维数据（>100 维）
- ❌ 非高斯分布
- ❌ 需要快速聚类（EM 算法慢）

### 6.3 对 AG News 聚类的最终建议

**算法排序（本任务）：**
1. **K-Means**: 简单、快速、效果与 GMM 相同
2. **GMM**: 提供不确定性分析，但慢且无实质改进
3. **DBSCAN**: 完全不适用

**根本问题：**
Gemini 嵌入优化于语义相似度检索，而非类别聚类。无论选择何种算法，纯度都难以超过 30%。

**改进方向：**
1. 监督微调嵌入（用分类任务）
2. 降维 + 聚类（PCA/UMAP → 50 维）
3. 深度聚类（DEC/IDEC）

---

## 7. 参考文献

### 核心算法
- **GMM**: McLachlan, G., & Peel, D. (2000). Finite Mixture Models. Wiley.
- **EM Algorithm**: Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum Likelihood from Incomplete Data via the EM Algorithm. *Journal of the Royal Statistical Society*, 39(1), 1-38.

### 模型选择
- **BIC**: Schwarz, G. (1978). Estimating the Dimension of a Model. *The Annals of Statistics*, 6(2), 461-464.
- **AIC**: Akaike, H. (1974). A New Look at the Statistical Model Identification. *IEEE Transactions on Automatic Control*, 19(6), 716-723.

### 数据集与工具
- **AG News**: Zhang, X., Zhao, J., & LeCun, Y. (2015). Character-level Convolutional Networks for Text Classification. *NeurIPS*, 28.
- **scikit-learn**: Pedregosa et al. (2011). Scikit-learn: Machine Learning in Python. *JMLR*, 12, 2825-2830.

---

## 附录A：协方差类型详细对比

### A.1 参数数量

| 协方差类型 | μ 参数 | Σ 参数 | π 参数 | 总参数 |
|-----------|--------|--------|--------|--------|
| Full | 4×768 | 4×(768×769/2) | 3 | 2,359,296 |
| Tied | 4×768 | 768×769/2 | 3 | 298,323 |
| Diag | 4×768 | 4×768 | 3 | 6,147 |
| Spherical | 4×768 | 4 | 3 | 3,079 |

**Full 参数是 Spherical 的 767 倍**！

### A.2 收敛性对比

| 协方差类型 | 收敛迭代 | 是否收敛 | 最终 Log-Likelihood |
|-----------|----------|----------|---------------------|
| Spherical | 7 | ✅ | -1089.80 |
| Diag | 8 | ✅ | -1089.79 |
| Tied | 8 | ✅ | -1088.57 |
| Full | 36 | ✅ | -1084.64 |

**Full 收敛最慢（36 次迭代），但 BIC 惩罚过高**。

---

## 附录B：软件环境

- **Python**: 3.12
- **scikit-learn**: 1.7.2
- **numpy**: 2.3.4
- **运行时间**: 814.8 秒（13.6 分钟）

---

**文档版本：** 1.0  
**最后更新：** 2025年11月10日  
**总页数：** 12
