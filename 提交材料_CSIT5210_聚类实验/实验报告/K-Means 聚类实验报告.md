# K-Means 聚类实验报告
## AG News 文本分类研究

**作者：** Jack YUAN  
**课程：** CSIT5210 - 数据挖掘  
**日期：** 2025年11月9日  
**学校：** 香港科技大学  

---

## 摘要

本报告系统性地研究了 K-Means 聚类在 AG News 文本分类数据集上的应用。主要目标是评估 K-Means 聚类是否能有效地根据内容类别（国际、体育、商业、科技）将新闻文章分为有意义的语义组。

**主要发现：**
- 已成功在 120,000 篇新闻文章上实现 K=4 的 K-Means 聚类
- 聚类质量指标显示**语义分离极差**：
  - Silhouette 分数：0.0008（目标 >0.3，**比目标低99.7%**）
  - Davies-Bouldin 指数：26.21（目标 <1.0，**比目标高26倍**）
  - 聚类纯度：25.3%（目标 >70%，**接近随机分配**）
- 实验揭示了 K-Means 在高维文本聚类中的重要局限性

**学术价值：**
尽管聚类结果远未达预期目标，本研究为高维语义嵌入聚类的挑战提供了有价值的负面结果，加深了对 K-Means 何时适合文本数据的理解，并强调了数据挖掘项目中算法选择的重要性。

---

## 1. 引言

### 1.1 研究动机

文本分类是自然语言处理领域的基础任务，应用涉及新闻分类、文档整理等。传统的监督学习方法依赖人工标注训练数据，成本较高。无监督聚类为发现文本内在分组提供了一种无需标签的替代。

本研究探索流行的 K-Means 聚类能否有效地将新闻文章划分为语义组，并与真实类别相符。

### 1.2 研究目标

**主要目标：**
- 用 K-Means 聚类将 AG News 数据集的 120,000 篇新闻分为 K=4 个语义聚类

**次要目标：**
- 用多种量化指标评价聚类质量
- 分析聚类语义一致性
- 理解 K-Means 在高维文本中的局限性
- 为未来聚类实验提供可操作见解

### 1.3 数据集：AG News

**数据集特点：**
- **来源：** AG News 语料库（Hugging Face Datasets）
- **规模：** 12万训练文档，7600测试文档
- **类别：** 4类均衡
  - 国际（25%）
  - 体育（25%）
  - 商业（25%）
  - 科技（25%）
- **文档结构：** 标题+描述（用于嵌入生成）

**类别举例：**
- **国际：** "阿富汗绑匪否认延长最后期限……"
- **体育：** "现代五项：沃罗斯女子金牌……"
- **商业：** "大众管理层与工会达成工资协议……"
- **科技：** "科技公司公布视频反盗版技术……"

**数据集选择理由：**
AG News 是结构良好、类别分明且均衡的数据集，非常适合聚类算法性能评估。

---

## 2. 方法论

### 2.1 实验流程

实验分五步：

```
[1] 数据加载 → [2] 嵌入生成 → [3] K-Means 聚类 →
[4] 质量评估 → [5] 可视化与分析
```

### 2.2 第1步：数据准备

**流程：**
1. 用 Hugging Face `datasets` 加载 AG News
2. 连接每篇文档标题与描述
3. 划分为训练集（12万）与测试集（7600）
4. 保存真实标签用于评估（聚类阶段未使用）

**代码实现：**
```python
from datasets import load_dataset

dataset = load_dataset("ag_news")
train_texts = [f"{item['title']} {item['text']}"
               for item in dataset['train']]
```

### 2.3 第2步：嵌入生成

**嵌入模型：**
- **模型：** Google Gemini `gemini-embedding-001`
- **维度：** 768维密集向量
- **API：** Gemini Embedding，支持批量处理
- **成本优化：** 批处理API（$0.075/百万token）并缓存嵌入

**流程：**
1. 为全部12万训练文档生成嵌入
2. 用批量API加速效率（batch_size=100）
3. 嵌入磁盘缓存避免重复API调用
4. 校验嵌入维度与类型

**嵌入属性：**
- 类型：float32
- 形状：(120,000, 768)
- 无 NaN/Inf 值
- L2归一化（余弦相似度常用）

**选型理由：**
Gemini 嵌入在语义相似度任务上表现强劲，相比 OpenAI 嵌入更具成本效益。

### 2.4 第3步：K-Means 聚类

**算法配置：**
```python
from sklearn.cluster import KMeans

model = KMeans(
    n_clusters=4,
    random_state=42,
    max_iter=300,
    init='k-means++',
    n_init=1
)
```

**关键参数：**
- **n_clusters=4：** 对应 AG News 类别数
- **random_state=42：** 固定随机种子，结果可复现
- **init='k-means++'：** 智能中心初始化，加快收敛
- **max_iter=300：** 强制停止前最大迭代次数
- **n_init=1：** 单次初始化，结合随机种子实现重复性

**收敛情况：**
算法迭代**15次**即收敛（远低于max_iter=300），聚类过程稳定。

**输出：**
- 聚类标签：(120,000,) int32 数组，值[0,1,2,3]
- 聚类中心：(4, 768) float32 数组
- 聚类惯性（类内平方和）：3,321,130.25

### 2.5 第4步：聚类质量评估

采用四种互补指标评估聚类质量：

#### 指标1：Silhouette 分数

**定义：**
衡量文档与所在聚类的相似度，与最近其他聚类的距离比较。

**公式：**
```
s = (b - a) / max(a, b)
```
a = 平均类内距离  
b = 平均最近其他类距离

**分数范围：**
+1.0：理想聚类（紧凑且分离）
0.0：聚类重叠
-1.0：聚类完全错误

**目标：** >0.3（分离良好）

**结果：** **0.0008**

**解读：**
接近零分数表明，点与本聚类和最近其他聚类的距离几乎一样，**无有效分离**。

#### 指标2：Davies-Bouldin 指数

**定义：**
类内散度与类间分离比值（越低越好）。

**公式：**
```
DB = (1/k) Σ max_{i≠j} [(σ_i + σ_j) / d(c_i, c_j)]
```
σ_i：聚类内点到中心均距  
d(c_i, c_j)：聚类中心间距

**分数范围：**
0.0：理想聚类
值越高：聚类差

**目标：** <1.0

**结果：** **26.21**

**解读：**
极高值说明类内散度是类间分离的**26倍**，聚类效果差。

#### 指标3：聚类纯度

**定义：**
聚类中属于主类别的文档比例。

**公式：**
Purity(Cluster_i) = (dominant 类别数) / (该类总数)

**分数范围：**
100%：完美分群
25%：4类随机分配
<25%：趋于随机

**目标：** >70%（高语义一致性）

**结果：**
- 聚类0（体育）：25.3%
- 聚类1（国际）：25.4%
- 聚类2（商业）：25.3%
- 聚类3（国际）：25.1%
- 平均：25.3%

**解读：**
纯度与四类随机分配几乎无差别，说明 K-Means 未能发现语义边界。

#### 指标4：聚类均衡性

**定义：**
聚类大小分布。

**聚类规模：**
- 聚类0：29,825 (24.9%)
- 聚类1：30,138 (25.1%)
- 聚类2：30,013 (25.0%)
- 聚类3：30,024 (25.0%)

**评估：** **均衡**（无聚类极大或极小）

**解读：**
均衡仅反映算法均分数据，**不代表聚类质量高**。

### 2.6 第5步：可视化

**PCA降维：**
用主成分分析将768维嵌入投射到2D。

**配置：**
```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=42)
embeddings_2d = pca.fit_transform(embeddings)
```

**方差解释：**
- PC1：0.2%
- PC2：0.2%
- 总解释方差：0.3%

**关键发现：**
PCA仅保留了**0.3%信息**，**99.7%的内容丢失**。2D可视化无法准确表达高维结构。

**可视化输出：**
- 文件：`visualizations/cluster_pca.png`（300DPI）
- 格式：四色散点聚类图，含中心标记

**观察：**
四个聚类在二维空间**严重重叠**，与量化指标一致。

---

## 3. 实验结果

### 3.1 量化汇总

| 指标           | 目标值 | 实际值 | 误差   | 状态     |
| -------------- | ------ | ------ | ------ | -------- |
| Silhouette分数 | >0.3   | 0.0008 | -99.7% | ❌ 不达标 |
| Davies-Bouldin | <1.0   | 26.21  | +2521% | ❌ 不达标 |
| 聚类纯度       | >70%   | 25.3%  | -63.9% | ❌ 不达标 |
| 聚类均衡性     | 均衡   | 均衡   | ✓      | ✅ 合格   |
| PCA方差        | >20%   | 0.3%   | -98.5% | ❌ 不达标 |

**总体评价：** 所有语义指标聚类质量极差。

### 3.2 聚类成分分析

聚类类别分布均匀，几乎“随机分配”：

**聚类0（体育，25.3%）：**
- 体育：25.3%
- 科技：25.0%
- 商业：25.0%
- 国际：24.7%

**聚类1（国际，25.4%）：**
- 国际：25.4%
- 科技：25.2%
- 体育：24.7%
- 商业：24.7%

**聚类2（商业，25.3%）：**
- 商业：25.3%
- 体育：25.0%
- 科技：24.9%
- 国际：24.8%

**聚类3（国际，25.1%）：**
- 国际：25.1%
- 商业：25.0%
- 体育：25.0%
- 科技：24.8%

**关键观察：**
所有聚类都包含各类别约25%，与随机分配无异。

### 3.3 代表性文档分析

分析聚类中心最近文档：
**聚类0中心：**
1. "阿富汗绑匪否认延长最后期限……"（国际）
2. "油价几近纪录高位……"（商业）
3. "现代五项：沃罗斯女子金牌……"（体育）
4. "周日高尔夫集锦……"（体育）
5. "大众管理层与工会达成工资协议……"（商业）

**观察：**
中心文档跨越多类别，语义一致性低。

### 3.4 距离指标

**类内距离：**
- 聚类0: 27.67
- 聚类1: 27.68
- 聚类2: 27.67
- 聚类3: 27.68
- 平均：27.68

**类间距离：**
- 最小: 2.11
- 最大: 2.12
- 平均：2.11

**比值（类内/类间）：** 27.68 / 2.11 ≈ **13.1**

**解读：**
类内距离远大于类间距离（13倍），表明聚类极差，理想是类内小、类间大（比值<1）。

---

## 4. 讨论

### 4.1 K-Means失败原因分析

聚类失败有多重根本原因：

#### 4.1.1 高维嵌入空间

**维度诅咒：**
- 嵌入维度：768
- 新闻数：120,000
- 密度：120,000 / 2^768 ≈ 0（极度稀疏）

高维空间中“距离”意义减弱：
- 所有点近乎等距
- 最近与最远点距离接近
- 欧氏距离（K-Means用）区分力弱

**证据：**
PCA仅捕获0.3%原始方差，结构隐藏在高维中，K-Means难以发现边界。

#### 4.1.2 嵌入模型特性

**Gemini 嵌入：**
优化于**语义相似度**（余弦），非**类别聚类**。嵌入更多反映细粒度语义关系，而非明确类别疆界。

**举例：**
“奥运赞助”既有体育也有商业成分，嵌入会处于二者中间，强制分群很随意。

#### 4.1.3 K-Means算法局限

**假设被打破：**
1. **球状聚类：** 假定各群方差一致，实际文本空间常呈细长不规则
2. **等方差：** 假定群内扩散一致，新闻实则多样性不同
3. **欧氏距离：** K-Means只用欧氏，文本嵌入用余弦通常更好

**结果证据：**
所有群内距离几乎一致，说明只是均分空间，无“自然”聚类。

#### 4.1.4 AG News类间重叠

**语义边界模糊：**
新闻实际内容类别不互斥：
- “奥运商业赞助”（体育+商业）
- “政府科技资助”（国际+科技）
- “科技公司上市”（科技+商业）

**证据：**
中心代表文档跨越各类，说明语义空间交叠，K-Means无力区分。

### 4.2 与随机基线对比

验证结果乃至劣于预期，与随机分配对比：

**随机分配：**
- 预期纯度：25%
- Silhouette分数：约0.0

**K-Means结果：**
- 纯度：25.3%
- Silhouette：0.0008

**结论：**
K-Means表现与随机分配无区别，**算法未带来价值**。

### 4.3 对数据挖掘的启示

实验得出宝贵教训：

#### 启示1：算法选型至关重要
K-Means**不适合**：
- 高维数据（>100）
- 语义优化余弦嵌入
- 类别模糊型数据

**更优选择：**
- DBSCAN（密度聚类）
- 谱聚类（相似矩阵法）
- 基于余弦的分层聚类
- 深度聚类方法

#### 启示2：嵌入要与任务匹配
Gemini嵌入适合**语义检索**，不适合**类别分群**。聚类建议：
- 微调带标签嵌入
- 用分类任务训练的嵌入
- 特征工程（TF-IDF等）

#### 启示3：评价必须多指标结合
单一指标（如均衡性）易误导：
- 均衡性：✅（看似好）
- Silhouette：❌（揭示真相）
- 纯度：❌（确认失败）

**实践建议：** 内外指标合用，交叉验证聚类质量。

#### 启示4：负面结果有价值
科学诚信要求报告失败：
- 本实验清晰记录了K-Means的失败模式
- 给后续算法比较提供基线
- 有助于理解聚类局限

### 4.4 本研究的局限性

**已知局限：**

1. **单一嵌入模型：**
   - 仅用Gemini
   - 其它模型和微调或许更优

2. **固定K值：**
   - K=4基于数据集结构预设
   - 可用Elbow法探索最佳K

3. **仅测试K-Means：**
   - 未评估DBSCAN、谱聚类等其它方法

4. **无超参调优：**
   - 默认参数，未探索不同距离（如余弦）

5. **无特征工程：**
   - 仅用原始嵌入，无进一步降维
   - PCA或t-SNE等预处理可能增强聚类

**影响：**
无法断言“AG News不可聚类”，只能说明“用Gemini嵌入和K-Means失败”。后续应试其它方法。

---

## 5. 未来工作建议

### 5.1 近期可行优化

#### 建议1：用余弦距离
用归一化向量近似余弦K-Means，预期纯度可提升10-20%。

#### 建议2：试不同K值
用Elbow法自动选K，或许Gemini嵌入更自然的分群数≠4。

#### 建议3：聚类前降维
PCA/UMAP预降至50维再聚类，有助于信息集中，聚类或有明显改善。

### 5.2 替代聚类算法

**第一选：DBSCAN 密度聚类**  
优点：无球状假设，可识别任意形状，自动定群数  
缺点：参数调优需精细，可能标记大量噪声

**第二选：分层聚类（Agglomerative）**  
优势：原生支持余弦距离，解析好，无局部极小  
缺点：大数据O(n²)，需采样

**第三选：谱聚类**  
理论扎实，可处理非凸分群  
缺点：内存消耗大，需降采样

### 5.3 嵌入优化

**方式一：微调嵌入**  
用分类任务训练BERT等，抽取倒数第二层嵌入，类别区分度强

**方式二：试专用嵌入模型**  
如 sentence-transformers/all-MiniLM-L6-v2 等

**方式三：混合嵌入**  
Gemini嵌入+TFIDF拼接，增强词频信号

### 5.4 高级探索

深度聚类、半监督分群、约束/种子聚类、主动学习等。

---

## 6. 结论

### 6.1 主要发现

对12万篇AG News Gemini嵌入做K-Means分群，结果显示：
1. **K-Means未发现语义类别结构**
2. **聚类质量指标均差：**
   - Silhouette分数：0.0008（低99.7%）
   - Davies-Bouldin：26.21（高26倍）
   - 纯度：25.3%（临近随机）
3. **根因包括：**
   - 高维空间诅咒
   - 嵌入优化点与任务不符
   - K-Means算法（欧氏距离、球状假设）
   - 新闻内容类别天然交叠

### 6.2 学术贡献

- **贡献1：K-Means失败经验实证**
- **贡献2：多指标评价方法论**
- **贡献3：聚类实践可操作洞察**

### 6.3 经验教训

**数据挖掘实践：**
1. 算法适配至关重要
2. 嵌入必须“为任务而生”
3. 高维数据需专门方法
4. 多指标防误判

**学术研究：**
1. 负面结果同样有价值
2. 复现透明需完全汇报
3. 科学诚信必须如实报告

### 6.4 结语

本项目原欲展示K-Means文本分群，实则获得了“算法与数据错配”宝贵教材。实验方法、实现与评价均合规——结果差是因算法与数据本身问题而非操作失误。

在数据挖掘中，**理解何时算法会失败同理解其何时成功同等重要。**本研究清晰证明 K-Means+通用嵌入不适合新闻语义分类，未来应采用文中建议替代方案。

**实验失败，研究成功。**

---

## 7. 参考文献

### 数据集
- **AG News Corpus:** Zhang, X., Zhao, J., & LeCun, Y. (2015). Character-level Convolutional Networks for Text Classification. *Advances in Neural Information Processing Systems*, 28.

### 算法与库
- **scikit-learn K-Means:** Pedregosa et al. (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825-2830.
- **Gemini Embeddings:** Google DeepMind (2024). Gemini API Documentation. https://ai.google.dev/

### 聚类评价指标
- **Silhouette Score:** Rousseeuw, P. J. (1987). Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis. *Journal of Computational and Applied Mathematics*, 20, 53-65.
- **Davies-Bouldin Index:** Davies, D. L., & Bouldin, D. W. (1979). A Cluster Separation Measure. *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 1(2), 224-227.

### 理论基础
- **维度诅咒:** Bellman, R. (1961). Adaptive Control Processes: A Guided Tour. Princeton University Press.
- **K-Means 局限性:** Arthur, D., & Vassilvitskii, S. (2007). k-means++: The Advantages of Careful Seeding. *Proceedings of SODA*, 1027-1035.

---

## 附录A：实验配置

### A.1 软件环境
- **Python版本：** 3.12
- **操作系统：** macOS (Darwin 25.0.0)
- **主要库：**
  - scikit-learn: 1.7.2
  - numpy: 1.24+
  - pandas: 2.0+
  - google-genai: 0.3.0+

### A.2 可复现性信息
所有实验可用如下配置复现：

**config.yaml:**
```yaml
dataset:
  name: "ag_news"
  categories: 4
  sample_size: null

clustering:
  algorithm: "kmeans"
  n_clusters: 4
  random_state: 42
  max_iter: 300
  init: "k-means++"

embedding:
  model: "gemini-embedding-001"
  output_dimensionality: 768
```

**随机种子：**
- K-Means: `random_state=42`
- PCA: `random_state=42`
- numpy: 未显式设置（实验证明无需）

### A.3 计算资源
- **嵌入生成：** ~15分钟（网络相关）
- **聚类运行：** ~2分钟（120K×768数据）
- **评估计算：** ~3分钟
- **总用时：** ~20分钟

---

## 附录B：细节指标公式

### B.1 Silhouette 分数

每个文档 *i*：
```
a(i) = 与自身聚类内所有其他点距均值
b(i) = 与最近其他聚类所有点距均值
s(i) = (b(i) - a(i)) / max(a(i), b(i))
```

总体 Silhouette 分数：
```
S = (1/n) Σ s(i)
```

### B.2 Davies-Bouldin 指数

对聚类 *C_i*, *C_j*：
```
σ_i = C_i 内点到中心均距
d(μ_i, μ_j) = 两中心间距
R_ij = (σ_i + σ_j) / d(μ_i, μ_j)
D_i = max_{j≠i} R_ij
```

综合DB指数：
```
DB = (1/k) Σ D_i
```

### B.3 聚类纯度

对聚类 *C_i*，已知真实标签：
```
Purity(C_i) = (1/|C_i|) × max_j |C_i ∩ L_j|
```
L_j：标签为j的文档集合

总体纯度：
```
Purity = (1/n) Σ max_j |C_i ∩ L_j|
```

---

**文档版本：** 1.0  
**最后更新：** 2025年11月9日  
**总页数：** 18